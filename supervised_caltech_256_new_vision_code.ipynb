{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from google.colab import drive, files\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import tarfile\n",
        "import warnings\n",
        "\n",
        "# ignore warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# saving the trained model\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 257  # 256 Categories + 1 Background Class\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-4\n",
        "SAVE_PATH = \"/content/drive/MyDrive/caltech256_resnet_optimal.pth\"\n",
        "DATA_DIR = \"/content/local_caltech256\"\n",
        "\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pGCZ5I2hW_Y",
        "outputId": "4a95d1b7-d195-4bbb-d74d-2f047c07b871"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This function is responsible for entire data pipeline eg, downloading, extracting.\n",
        "def setup_data():\n",
        "\n",
        "    # if dataset not in local device, download it\n",
        "    if not os.path.exists(DATA_DIR):\n",
        "        print(\"Downloading the dataset(caltech 256)\")\n",
        "        os.system(\"wget -q https://data.caltech.edu/records/nyy15-4j048/files/256_ObjectCategories.tar -O caltech256.tar\")\n",
        "\n",
        "        print(\"Extracting, please wait!\")\n",
        "        with tarfile.open('caltech256.tar') as tar_file:\n",
        "            tar_file.extractall(path='/content')\n",
        "        if os.path.exists(\"/content/256_ObjectCategories\"):\n",
        "            os.rename(\"/content/256_ObjectCategories\", DATA_DIR)\n",
        "\n",
        "        if os.path.exists('caltech256.tar'):\n",
        "            os.remove('caltech256.tar')\n",
        "\n",
        "    # transformer defining\n",
        "    train_transform = transforms.Compose([transforms.Resize((384, 384)),\n",
        "                                          transforms.TrivialAugmentWide(),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    val_transform = transforms.Compose([transforms.Resize((384, 384)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    # loading the dataset\n",
        "    full_dataset = datasets.ImageFolder(root=DATA_DIR)\n",
        "\n",
        "    torch.manual_seed(42) # train and val split same\n",
        "    train_length = int(0.8 * len(full_dataset))\n",
        "    val_length = len(full_dataset) - train_length\n",
        "    train_set, val_set = random_split(full_dataset, [train_length, val_length])\n",
        "\n",
        "    # assigning specific transforms to the subsets\n",
        "    train_set.dataset.transform = train_transform\n",
        "    val_set.dataset.transform = val_transform\n",
        "    dataloaders_dict = {'train': DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True),\n",
        "                        'val': DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)}\n",
        "\n",
        "    return dataloaders_dict, full_dataset.classes"
      ],
      "metadata": {
        "id": "Pu_mKVf_hZbh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the ResNet50 model pre-trained on ImageNet.\n",
        "def get_resnet_model():\n",
        "\n",
        "    # Loading V2 weights\n",
        "    weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
        "    model = models.resnet50(weights=weights)\n",
        "\n",
        "    # Freezing the first few blocks\n",
        "    for parameter_name, parameter in model.named_parameters():\n",
        "        if \"layer1\" in parameter_name or \"conv1\" in parameter_name or \"bn1\" in parameter_name:\n",
        "            parameter.requires_grad = False\n",
        "\n",
        "    # Replace the final classification layer\n",
        "    input_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(input_features, NUM_CLASSES)\n",
        "\n",
        "    return model.to(DEVICE)"
      ],
      "metadata": {
        "id": "hX5KsDuphblX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is teh main training loop and it will returns the model and the training history for the plotting.\n",
        "def train_model(model, loaders):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "    accuracy_history = []\n",
        "    print(f\"Training started for {EPOCHS} epochs.\")\n",
        "\n",
        "    for epoch_index in range(EPOCHS):\n",
        "        start_time = time.time()\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            running_loss = 0.0\n",
        "            correct_predictions = 0\n",
        "\n",
        "            for input_images, labels in loaders[phase]:\n",
        "                input_images = input_images.to(DEVICE)\n",
        "                labels = labels.to(DEVICE)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # autocast enables mixed precision (FP16)\n",
        "                with autocast():\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(input_images)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        max_probs, predicted_classes = torch.max(outputs, 1)\n",
        "\n",
        "                        if phase == 'train':\n",
        "                            scaler.scale(loss).backward()\n",
        "                            scaler.step(optimizer)\n",
        "                            scaler.update()\n",
        "                running_loss += loss.item() * input_images.size(0)\n",
        "                correct_predictions += torch.sum(predicted_classes == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            # Logging\n",
        "            dataset_size = len(loaders[phase].dataset)\n",
        "            epoch_loss = running_loss / dataset_size\n",
        "            epoch_accuracy = correct_predictions.double() / dataset_size\n",
        "\n",
        "            if phase == 'val':\n",
        "                elapsed_time = (time.time() - start_time) / 60\n",
        "                print(f\"Epoch {epoch_index+1}/{EPOCHS} | Loss: {epoch_loss:.4f} | Acc: {epoch_accuracy*100:.2f}% | Time: {elapsed_time:.1f} min\")\n",
        "\n",
        "                # Store accuracy for plot\n",
        "                accuracy_history.append(epoch_accuracy.item()*100)\n",
        "\n",
        "                # Save the best model found so far\n",
        "                if epoch_accuracy > best_accuracy:\n",
        "                    best_accuracy = epoch_accuracy\n",
        "                    torch.save(model.state_dict(), 'temp_best.pth')\n",
        "\n",
        "    print(f\"Training finished. Best Validation Accuracy: {best_accuracy*100:.2f}%\")\n",
        "\n",
        "    # Reload the absolute best weights before returning\n",
        "    model.load_state_dict(torch.load('temp_best.pth'))\n",
        "    return model, accuracy_history"
      ],
      "metadata": {
        "id": "CMPnk7kBhei2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates accuracy on the dataset without training.\n",
        "def evaluate_accuracy(model, loader):\n",
        "\n",
        "    model.eval()\n",
        "    correct_count = 0\n",
        "    total_count = 0\n",
        "\n",
        "    print(\"Calculating current accuracy...\")\n",
        "    with torch.no_grad():\n",
        "        for input_images, labels in loader:\n",
        "            input_images = input_images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            outputs = model(input_images)\n",
        "            max_scores, predicted_classes = torch.max(outputs.data, 1)\n",
        "            total_count += labels.size(0)\n",
        "            correct_count += (predicted_classes == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct_count / total_count\n",
        "    print(f\"Current Model Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "91xIIXMGhf0Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finds the top 5 most confused pairs of classes.\n",
        "def show_confusion_errors(model, loader):\n",
        "\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "\n",
        "    print(\"\\nAnalyzing confusion matrix...\")\n",
        "    with torch.no_grad():\n",
        "        for input_images, labels in loader:\n",
        "            input_images = input_images.to(DEVICE)\n",
        "            outputs = model(input_images)\n",
        "            max_scores, predicted_classes = torch.max(outputs, 1)\n",
        "\n",
        "            all_predictions.extend(predicted_classes.cpu().numpy())\n",
        "            all_true_labels.extend(labels.numpy())\n",
        "\n",
        "    # confusion matrix\n",
        "    confusion_mat = confusion_matrix(all_true_labels, all_predictions)\n",
        "    np.fill_diagonal(confusion_mat, 0) # Ignore correct predictions\n",
        "\n",
        "    # Sort by error count\n",
        "    top_error_indices = np.argsort(confusion_mat.flatten())[-5:]\n",
        "    class_names = loader.dataset.dataset.classes\n",
        "\n",
        "    print(\"Top 5 Confused Pairs:\")\n",
        "    for flat_index in top_error_indices:\n",
        "        true_class_index, predicted_class_index = divmod(flat_index, NUM_CLASSES)\n",
        "        error_count = confusion_mat[true_class_index, predicted_class_index]\n",
        "        print(f\"True: {class_names[true_class_index]} | Pred: {class_names[predicted_class_index]} | Count: {error_count}\")"
      ],
      "metadata": {
        "id": "oeW5TyCChiES"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # preparing the data\n",
        "    dataloaders_dict, all_class_names = setup_data()\n",
        "\n",
        "    # initialize the model\n",
        "    resnet_model = get_resnet_model()\n",
        "\n",
        "    training_history = []\n",
        "\n",
        "    # check if we already have a saved model\n",
        "    if os.path.exists(SAVE_PATH):\n",
        "        print(f\"Found saved model at {SAVE_PATH}\")\n",
        "        print(\"Loading weights!!!\")\n",
        "        resnet_model.load_state_dict(torch.load(SAVE_PATH, map_location=DEVICE))\n",
        "\n",
        "        # if model is loaded, just check accuracy\n",
        "        evaluate_accuracy(resnet_model, dataloaders_dict['val'])\n",
        "        trained_model = resnet_model\n",
        "\n",
        "    else:\n",
        "        print(\"No saved model found. Training from scratch...\")\n",
        "        trained_model, training_history = train_model(resnet_model, dataloaders_dict)\n",
        "\n",
        "        # save to Google Drive\n",
        "        torch.save(trained_model.state_dict(), SAVE_PATH)\n",
        "        print(f\"Model saved to {SAVE_PATH}\")\n",
        "\n",
        "    # run the analysis\n",
        "    show_confusion_errors(trained_model, dataloaders_dict['val'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV-jdAtLhtD5",
        "outputId": "b81402de-9d60-4818-879d-b04088644600"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the dataset(caltech 256)\n",
            "Extracting, please wait!\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 188MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found saved model at /content/drive/MyDrive/caltech256_resnet_optimal.pth\n",
            "Loading weights!!!\n",
            "Calculating current accuracy...\n",
            "Current Model Accuracy: 90.33%\n",
            "\n",
            "Analyzing confusion matrix...\n",
            "Top 5 Confused Pairs:\n",
            "True: 232.t-shirt | Pred: 159.people | Count: 4\n",
            "True: 026.cake | Pred: 159.people | Count: 4\n",
            "True: 191.sneaker | Pred: 255.tennis-shoes | Count: 4\n",
            "True: 069.fighter-jet | Pred: 251.airplanes-101 | Count: 6\n",
            "True: 255.tennis-shoes | Pred: 191.sneaker | Count: 8\n"
          ]
        }
      ]
    }
  ]
}